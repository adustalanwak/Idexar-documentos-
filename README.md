# ğŸ“š PDF Indexer Pro - Sistema Inteligente de Consulta de PDFs

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![PyQt5](https://img.shields.io/badge/GUI-PyQt5-green.svg)
![Ollama](https://img.shields.io/badge/LLM-Ollama-orange.svg)
![RAG](https://img.shields.io/badge/Architecture-RAG-purple.svg)

Una aplicaciÃ³n de escritorio inteligente que indexa y consulta documentos PDF usando modelos de lenguaje local (LLM) mediante Ollama y tecnologÃ­a RAG (Retrieval-Augmented Generation).

## ğŸš€ CaracterÃ­sticas Principales

- **ğŸ“„ IndexaciÃ³n Inteligente**: Extrae texto de PDFs (digitales y escaneados)
- **ğŸ¤– Resumen AutomÃ¡tico**: Genera resÃºmenes con modelos Llama3
- **ğŸ” Consulta SemÃ¡ntica**: BÃºsqueda conversacional en documentos indexados
- **ğŸ’¾ Almacenamiento Vectorial**: Usa FAISS para bÃºsquedas eficientes
- **ğŸ–¥ï¸ Interfaz GrÃ¡fica**: AplicaciÃ³n de escritorio con PyQt5
- **ğŸŒ Soporte EspaÃ±ol**: OCR y procesamiento optimizado para espaÃ±ol

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### **Backend**
- **Python 3.8+** - Lenguaje principal
- **PyQt5** - Interfaz grÃ¡fica de usuario
- **PyMuPDF (fitz)** - Procesamiento de PDFs
- **pytesseract** - OCR para documentos escaneados
- **Ollama** - Modelos de lenguaje local
- **LangChain** - Framework para aplicaciones con LLMs
- **FAISS** - Almacenamiento y bÃºsqueda vectorial
- **SQLite** - Base de datos para metadatos

### **Modelos**
- **Llama3** - Modelo de lenguaje principal
- **OllamaEmbeddings** - GeneraciÃ³n de embeddings

## âš™ï¸ InstalaciÃ³n

### Prerrequisitos
1. **Ollama instalado y ejecutÃ¡ndose**
```bash
# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Descargar modelo Llama3
ollama pull llama3
